# Regression and model validation
## Data wrangling 

see chap2_wrangling.R

## Graphical overview of the data

### 1 The Data

```{r warning=FALSE}
# load data
lrn14 <- read.csv("http://s3.amazonaws.com/assets.datacamp.com/production/course_2218/datasets/learning2014.txt", sep=",")
str (lrn14)
dim (lrn14)
```

The dataframe consists of 166 observations for 7 variables (gender, age, attitude, deep, stra, surf and points)


### 2 Graphs to visualize the overall relationships between all the selected variables 

```{r warning=FALSE}
##### load libraries
library(GGally)
library(ggplot2)

# draw all possible scatterplots to explore the data frame
plot_data <- ggpairs (lrn14, mapping = aes(col = gender, alpha = 0.3), lower = list(combo = wrap("facethist", bins = 20)))

####Draw the plot and summarise
plot_data
summary(lrn14)
```

Total number of males are 50% less than females.
Mainly in Attitude the differences between gender are more noticeable 


Based in the previous observations it seems interesting to visualize how the attitute (that seems to vary most with gender) correlates with the acquired Points. 

### 3 Regression model (exploration)

```{r}
regression_model <- lm(points ~ attitude + deep + stra + surf, data = lrn14)
summary(regression_model)
```
In this multivariant analysis, we "measure" points against attitude, deep, stra and surf i.e. the explainatory variables and see that points have significant relationship with attitude.
R-squared value of 0.22 implies that the model can explain 22% of the variation in the outcome.

### 3 Regression model (new)

```{r}
new_regression_model <- lm(points ~ attitude, data = lrn14)
summary(new_regression_model)
```

### 4 Interpret the model parameters after removing non-significant parameters

```{r}
summary(new_regression_model)
```

Points is significantly related to attitude 
Multiple R-squared:  0.1906
R-squared = Explained variation / Total variation
Multiple R-squared is used for evaluating how well the model fits the data. In this case, R-squared value of 0.19 implies that the model can explain only 19% of the variation in the outcome.

### 5 Diagnostic plots

```{r}
plot(new_regression_model, which = c(1, 2, 5), par(mfrow = c(2,2)) )
```


Assumptions of the model:
1. How well does the model describs the variables we are interested in
2. The target variable is a linear combination of the model parameters
3. Errors are normally disrtibuted, not correlated and have constant variance

Residual vs Fitted plot explains about variance in errors. 
We can see that some errors deviate from the regression line implying that there is issue with the model.

QQplot shows that most points fall close to the line but some points are not close on the left hand side of the graph, hence the fit is somewhere near to the normality assumption. The model is reasonably okay.

Leverage plot shows the impact of a single observation on the model. 
There are some observations (values of -3) that have a high impact on the model which is not good.